<!DOCTYPE html>
<html>
<head>
    <script src="../jspsych.js"></script>
    <script src="../plugins/jspsych-image-audio-response.js"></script>
    <link rel="stylesheet" href="../css/jspsych.css"></link>
    <style>
        img { width: 300px; }
    </style>
</head>
<body></body>
<script>

    // By default, the audio will be saved as a JSON/CSV-friendly base64 string and will need to be converted back to
    // an audio file offline. This can be done using existing functions in R (base64enc package) or Python (base64
    // library). You can also test the conversion using an online base64-to-audio converter like this one: 
    // https://base64.guru/converter/decode/audio
    // The default postprocessing function can be overwritten by passing a custom function to the 'postprocessing' 
    // parameter. This provides the option to save the data as an audio file rather than a string.
    // See the plugin documentation for more details. 

    let timeline = [];

    timeline.push({
        type: 'image-audio-response',
        stimulus: 'img/happy_face_1.jpg',
        prompt: "<p>What emotion is this person showing?</p>",
        allow_playback: true,
        buffer_length: 6000,
        wait_for_mic_approval: true
    });

    timeline.push({
        type: 'image-audio-response',
        stimulus: 'img/happy_face_2.jpg',
        stimulus_duration: 1000,
        prompt: "<p>What emotion is this person showing? (image disappears after 1s)</p>",
        allow_playback: true
    });

    timeline.push({
        type: 'image-audio-response',
        stimulus: 'img/happy_face_3.jpg',
        response_ends_trial: true,
        prompt: "<p>What emotion is this person showing? (trial ends after response)</p>"
    });

    jsPsych.init({
        timeline: timeline,
        on_finish: function(){
            jsPsych.data.displayData();
        }
    });

</script>
</html>
